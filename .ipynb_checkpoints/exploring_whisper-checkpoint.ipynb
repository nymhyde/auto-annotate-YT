{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d264b9-e3d3-4426-b117-66fca13f92c4",
   "metadata": {},
   "source": [
    "## Exploring OpenAI's Whisper model for YouTube video transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ebc5bb-07c7-4999-b340-6f6aa1899b13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-6sanp4wl\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-6sanp4wl\n",
      "  Resolved https://github.com/openai/whisper.git to commit b5851c6c40e753606765ac45b85b298e3ae9e00d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ffmpeg-python==0.2.0 in /home/batman/.local/lib/python3.10/site-packages (from openai-whisper==20230314) (0.2.0)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper==20230314) (8.10.0)\n",
      "Requirement already satisfied: torch in /home/batman/.local/lib/python3.10/site-packages (from openai-whisper==20230314) (2.1.0.dev20230310+cu117)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/batman/.local/lib/python3.10/site-packages (from openai-whisper==20230314) (2.0.0)\n",
      "Requirement already satisfied: numba in /home/batman/.local/lib/python3.10/site-packages (from openai-whisper==20230314) (0.56.0)\n",
      "Requirement already satisfied: numpy in /home/batman/.local/lib/python3.10/site-packages (from openai-whisper==20230314) (1.22.4)\n",
      "Requirement already satisfied: tqdm in /home/batman/.local/lib/python3.10/site-packages (from openai-whisper==20230314) (4.64.0)\n",
      "Requirement already satisfied: tiktoken==0.3.1 in /home/batman/.local/lib/python3.10/site-packages (from openai-whisper==20230314) (0.3.1)\n",
      "Requirement already satisfied: future in /home/batman/.local/lib/python3.10/site-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/batman/.local/lib/python3.10/site-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/batman/.local/lib/python3.10/site-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
      "Requirement already satisfied: cmake in /home/batman/.local/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/batman/.local/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314) (15.0.7)\n",
      "Requirement already satisfied: filelock in /home/batman/.local/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314) (3.9.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/batman/.local/lib/python3.10/site-packages (from numba->openai-whisper==20230314) (0.39.0)\n",
      "Requirement already satisfied: setuptools in /home/batman/.local/lib/python3.10/site-packages (from numba->openai-whisper==20230314) (67.6.0)\n",
      "Requirement already satisfied: sympy in /home/batman/.local/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /home/batman/.local/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in /home/batman/.local/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
      "Requirement already satisfied: networkx in /home/batman/.local/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (3.0rc1)\n",
      "Requirement already satisfied: pytorch-triton==2.0.0+b8b470bc59 in /home/batman/.local/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (2.0.0+b8b470bc59)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/batman/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/batman/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/batman/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/batman/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/batman/.local/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/batman/.local/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20230314) (1.2.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/pytube/pytube.git\n",
      "  Cloning https://github.com/pytube/pytube.git to /tmp/pip-req-build-emj5vd4n\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/pytube/pytube.git /tmp/pip-req-build-emj5vd4n\n",
      "  Resolved https://github.com/pytube/pytube.git to commit 96315dff218c3c5c4621997a5587f9d677774b97\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/batman/.local/lib/python3.10/site-packages (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/batman/.local/lib/python3.10/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/batman/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "! pip install git+https://github.com/pytube/pytube.git\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be980488-a603-4386-83ec-512dc76d017e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import torch\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62edf7c6-b439-4f3d-851f-ce3765e77d95",
   "metadata": {},
   "source": [
    "### Download the YT video as audio format\n",
    "---\n",
    "- Download the given `url` from YouTube as audio only format and save it locally.\n",
    "- This audio file will be fed to the whisper model.\n",
    "- `last()` selects the highets bit-rate audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9951a567-de75-4cd7-824b-6629500b81f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yt_url = \"https://youtu.be/ORMx45xqWkA\"\n",
    "audio_input = YouTube(yt_url).streams.filter(only_audio=True).last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54c06406-d090-4bd5-91dd-49d2267d4d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5440a3c0-112d-4aa2-8bf0-c4a887d89416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_input = audio_input.download(\"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38f785cf-95d0-441d-bdb7-27dba182f425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/batman/fun/auto-annotate-YT/audio/PyTorch in 100 Seconds.mp4'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80297c-3050-4794-88c8-162fa389351e",
   "metadata": {},
   "source": [
    "### Load the Whisper Model\n",
    "---\n",
    "- We will be using the `base` multi-language model.\n",
    "- It has 74 M parameters.\n",
    "\n",
    "- ***All other models***\n",
    "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
    "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
    "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
    "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
    "| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
    "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
    "| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f58eb3f0-fa10-4cbf-b9dd-fd4bb19df558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = whisper.load_model(\"base\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff35e3-834f-45e8-9e2b-6e52dd3f86f9",
   "metadata": {},
   "source": [
    "### Transcribe the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42af8e0c-da61-4257-828d-054f5c337c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transcription = model.transcribe(audio_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6536cc97-a8a4-4847-a703-7a93ecdad616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" The Pi Torch, an open-source deep learning framework used to build some of the world's most famous artificial intelligence products. It was created at the Meta AI Research Lab in 2016, but is actually derived from the Lua-based torch library that dates back to 2002. Fundamentally, it's a library for programming with tensors, which are basically just multidimensional arrays that represent data and parameters in deep neural networks. Sounds complicated, but its focus on usability will have you training machine learning models with just a few lines of Python. In addition, it facilitates high-performance parallel computing on a GPU, thanks to Nvidia's CUDA platform. Developers love prototyping with it, because it supports a dynamic computation graph, allowing models to be optimized at runtime. It does this by constructing a directed A-cyclic graph consisting of functions that keeps track of all the executed operations on the tensors, allowing you to change the shape, size, and operations after every iteration if needed. Pi Torch has been used to train models for computer vision AI like Tesla Autopilot, image generators like stable diffusion, and speech recognition models like OpenAI Whisper, just to name a few. To get started, install Pi Torch and optionally CUDA if you want to accelerate computing on your GPU. Now, import it into a Python file or notebook, like I mentioned, a tensor is similar to a multidimensional array, create a 2D array or matrix with Python, then use Torch to convert it into a tensor. Now, we can run all kinds of computations on it, like we might convert all these integers into random floating points. We can also perform linear algebra by taking multiple tensors and multiplying them together. What you came here to do, though, is build a deep neural network, like an image classifier. To handle that, we can define a new class that inherits from the neural network module class. Inside the constructor, we can build it out layer by layer. The flatten layer will take a multidimensional input, like an image, and convert it to one dimension. From there, sequential as use, you create a container of layers that the data will flow through. Each layer has multiple nodes, where each node is like its own mini statistical model, as each data point flows through it, it will try to guess the output, and gradually update a mapping of weights to determine the importance of a given variable. Linear is a fully connected layer that takes the flatten 28x28 image and transforms it to an output of 512. This layer is followed by a non-linear activation function. When activated, it means that feature might be important, and outputs the node, otherwise it just outputs zero. And finally, we finish with a fully connected layer that outputs the 10 labels the model is trying to predict. With these pieces in place, that next step is to define a forward method that describes the flow of data, and now instantiate the model to a GPU, and pass its input data. This will automatically call its forward method, for training and prediction. Congratulations, you just built a neural network. This has been PyTorch in 100 seconds. Thanks for watching, and I will see you in the next one.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 4.5600000000000005,\n",
       "   'text': \" The Pi Torch, an open-source deep learning framework used to build some of the world's most\",\n",
       "   'tokens': [50364,\n",
       "    440,\n",
       "    17741,\n",
       "    7160,\n",
       "    339,\n",
       "    11,\n",
       "    364,\n",
       "    1269,\n",
       "    12,\n",
       "    41676,\n",
       "    2452,\n",
       "    2539,\n",
       "    8388,\n",
       "    1143,\n",
       "    281,\n",
       "    1322,\n",
       "    512,\n",
       "    295,\n",
       "    264,\n",
       "    1002,\n",
       "    311,\n",
       "    881,\n",
       "    50592],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 4.5600000000000005,\n",
       "   'end': 9.76,\n",
       "   'text': ' famous artificial intelligence products. It was created at the Meta AI Research Lab in 2016,',\n",
       "   'tokens': [50592,\n",
       "    4618,\n",
       "    11677,\n",
       "    7599,\n",
       "    3383,\n",
       "    13,\n",
       "    467,\n",
       "    390,\n",
       "    2942,\n",
       "    412,\n",
       "    264,\n",
       "    6377,\n",
       "    64,\n",
       "    7318,\n",
       "    10303,\n",
       "    10137,\n",
       "    294,\n",
       "    6549,\n",
       "    11,\n",
       "    50852],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 9.76,\n",
       "   'end': 14.48,\n",
       "   'text': ' but is actually derived from the Lua-based torch library that dates back to 2002.',\n",
       "   'tokens': [50852,\n",
       "    457,\n",
       "    307,\n",
       "    767,\n",
       "    18949,\n",
       "    490,\n",
       "    264,\n",
       "    441,\n",
       "    4398,\n",
       "    12,\n",
       "    6032,\n",
       "    27822,\n",
       "    6405,\n",
       "    300,\n",
       "    11691,\n",
       "    646,\n",
       "    281,\n",
       "    17822,\n",
       "    13,\n",
       "    51088],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': 14.48,\n",
       "   'end': 18.48,\n",
       "   'text': \" Fundamentally, it's a library for programming with tensors, which are basically just\",\n",
       "   'tokens': [51088,\n",
       "    13493,\n",
       "    2466,\n",
       "    379,\n",
       "    11,\n",
       "    309,\n",
       "    311,\n",
       "    257,\n",
       "    6405,\n",
       "    337,\n",
       "    9410,\n",
       "    365,\n",
       "    10688,\n",
       "    830,\n",
       "    11,\n",
       "    597,\n",
       "    366,\n",
       "    1936,\n",
       "    445,\n",
       "    51288],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 4,\n",
       "   'seek': 0,\n",
       "   'start': 18.48,\n",
       "   'end': 22.96,\n",
       "   'text': ' multidimensional arrays that represent data and parameters in deep neural networks.',\n",
       "   'tokens': [51288,\n",
       "    2120,\n",
       "    327,\n",
       "    332,\n",
       "    11075,\n",
       "    41011,\n",
       "    300,\n",
       "    2906,\n",
       "    1412,\n",
       "    293,\n",
       "    9834,\n",
       "    294,\n",
       "    2452,\n",
       "    18161,\n",
       "    9590,\n",
       "    13,\n",
       "    51512],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 5,\n",
       "   'seek': 0,\n",
       "   'start': 22.96,\n",
       "   'end': 27.04,\n",
       "   'text': ' Sounds complicated, but its focus on usability will have you training machine learning models',\n",
       "   'tokens': [51512,\n",
       "    14576,\n",
       "    6179,\n",
       "    11,\n",
       "    457,\n",
       "    1080,\n",
       "    1879,\n",
       "    322,\n",
       "    46878,\n",
       "    486,\n",
       "    362,\n",
       "    291,\n",
       "    3097,\n",
       "    3479,\n",
       "    2539,\n",
       "    5245,\n",
       "    51716],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 6,\n",
       "   'seek': 2704,\n",
       "   'start': 27.04,\n",
       "   'end': 31.119999999999997,\n",
       "   'text': ' with just a few lines of Python. In addition, it facilitates high-performance parallel',\n",
       "   'tokens': [50364,\n",
       "    365,\n",
       "    445,\n",
       "    257,\n",
       "    1326,\n",
       "    3876,\n",
       "    295,\n",
       "    15329,\n",
       "    13,\n",
       "    682,\n",
       "    4500,\n",
       "    11,\n",
       "    309,\n",
       "    10217,\n",
       "    30035,\n",
       "    1090,\n",
       "    12,\n",
       "    50242,\n",
       "    8952,\n",
       "    50568],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 7,\n",
       "   'seek': 2704,\n",
       "   'start': 31.119999999999997,\n",
       "   'end': 36.4,\n",
       "   'text': \" computing on a GPU, thanks to Nvidia's CUDA platform. Developers love prototyping with it,\",\n",
       "   'tokens': [50568,\n",
       "    15866,\n",
       "    322,\n",
       "    257,\n",
       "    18407,\n",
       "    11,\n",
       "    3231,\n",
       "    281,\n",
       "    46284,\n",
       "    311,\n",
       "    29777,\n",
       "    7509,\n",
       "    3663,\n",
       "    13,\n",
       "    11442,\n",
       "    433,\n",
       "    959,\n",
       "    46219,\n",
       "    3381,\n",
       "    365,\n",
       "    309,\n",
       "    11,\n",
       "    50832],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 8,\n",
       "   'seek': 2704,\n",
       "   'start': 36.4,\n",
       "   'end': 41.04,\n",
       "   'text': ' because it supports a dynamic computation graph, allowing models to be optimized at runtime.',\n",
       "   'tokens': [50832,\n",
       "    570,\n",
       "    309,\n",
       "    9346,\n",
       "    257,\n",
       "    8546,\n",
       "    24903,\n",
       "    4295,\n",
       "    11,\n",
       "    8293,\n",
       "    5245,\n",
       "    281,\n",
       "    312,\n",
       "    26941,\n",
       "    412,\n",
       "    34474,\n",
       "    13,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 9,\n",
       "   'seek': 2704,\n",
       "   'start': 41.04,\n",
       "   'end': 46.32,\n",
       "   'text': ' It does this by constructing a directed A-cyclic graph consisting of functions that keeps track of',\n",
       "   'tokens': [51064,\n",
       "    467,\n",
       "    775,\n",
       "    341,\n",
       "    538,\n",
       "    39969,\n",
       "    257,\n",
       "    12898,\n",
       "    316,\n",
       "    12,\n",
       "    1344,\n",
       "    66,\n",
       "    1050,\n",
       "    4295,\n",
       "    33921,\n",
       "    295,\n",
       "    6828,\n",
       "    300,\n",
       "    5965,\n",
       "    2837,\n",
       "    295,\n",
       "    51328],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 10,\n",
       "   'seek': 2704,\n",
       "   'start': 46.32,\n",
       "   'end': 51.04,\n",
       "   'text': ' all the executed operations on the tensors, allowing you to change the shape, size, and operations',\n",
       "   'tokens': [51328,\n",
       "    439,\n",
       "    264,\n",
       "    17577,\n",
       "    7705,\n",
       "    322,\n",
       "    264,\n",
       "    10688,\n",
       "    830,\n",
       "    11,\n",
       "    8293,\n",
       "    291,\n",
       "    281,\n",
       "    1319,\n",
       "    264,\n",
       "    3909,\n",
       "    11,\n",
       "    2744,\n",
       "    11,\n",
       "    293,\n",
       "    7705,\n",
       "    51564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 11,\n",
       "   'seek': 2704,\n",
       "   'start': 51.04,\n",
       "   'end': 55.6,\n",
       "   'text': ' after every iteration if needed. Pi Torch has been used to train models for computer vision AI',\n",
       "   'tokens': [51564,\n",
       "    934,\n",
       "    633,\n",
       "    24784,\n",
       "    498,\n",
       "    2978,\n",
       "    13,\n",
       "    17741,\n",
       "    7160,\n",
       "    339,\n",
       "    575,\n",
       "    668,\n",
       "    1143,\n",
       "    281,\n",
       "    3847,\n",
       "    5245,\n",
       "    337,\n",
       "    3820,\n",
       "    5201,\n",
       "    7318,\n",
       "    51792],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 12,\n",
       "   'seek': 5560,\n",
       "   'start': 55.68,\n",
       "   'end': 60.56,\n",
       "   'text': ' like Tesla Autopilot, image generators like stable diffusion, and speech recognition models',\n",
       "   'tokens': [50368,\n",
       "    411,\n",
       "    13666,\n",
       "    6049,\n",
       "    404,\n",
       "    31516,\n",
       "    11,\n",
       "    3256,\n",
       "    38662,\n",
       "    411,\n",
       "    8351,\n",
       "    25242,\n",
       "    11,\n",
       "    293,\n",
       "    6218,\n",
       "    11150,\n",
       "    5245,\n",
       "    50612],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 13,\n",
       "   'seek': 5560,\n",
       "   'start': 60.56,\n",
       "   'end': 65.6,\n",
       "   'text': ' like OpenAI Whisper, just to name a few. To get started, install Pi Torch and optionally CUDA',\n",
       "   'tokens': [50612,\n",
       "    411,\n",
       "    7238,\n",
       "    48698,\n",
       "    41132,\n",
       "    610,\n",
       "    11,\n",
       "    445,\n",
       "    281,\n",
       "    1315,\n",
       "    257,\n",
       "    1326,\n",
       "    13,\n",
       "    1407,\n",
       "    483,\n",
       "    1409,\n",
       "    11,\n",
       "    3625,\n",
       "    17741,\n",
       "    7160,\n",
       "    339,\n",
       "    293,\n",
       "    3614,\n",
       "    379,\n",
       "    29777,\n",
       "    7509,\n",
       "    50864],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 14,\n",
       "   'seek': 5560,\n",
       "   'start': 65.6,\n",
       "   'end': 70.56,\n",
       "   'text': ' if you want to accelerate computing on your GPU. Now, import it into a Python file or notebook,',\n",
       "   'tokens': [50864,\n",
       "    498,\n",
       "    291,\n",
       "    528,\n",
       "    281,\n",
       "    21341,\n",
       "    15866,\n",
       "    322,\n",
       "    428,\n",
       "    18407,\n",
       "    13,\n",
       "    823,\n",
       "    11,\n",
       "    974,\n",
       "    309,\n",
       "    666,\n",
       "    257,\n",
       "    15329,\n",
       "    3991,\n",
       "    420,\n",
       "    21060,\n",
       "    11,\n",
       "    51112],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 15,\n",
       "   'seek': 5560,\n",
       "   'start': 70.56,\n",
       "   'end': 76.16,\n",
       "   'text': ' like I mentioned, a tensor is similar to a multidimensional array, create a 2D array or matrix with Python,',\n",
       "   'tokens': [51112,\n",
       "    411,\n",
       "    286,\n",
       "    2835,\n",
       "    11,\n",
       "    257,\n",
       "    40863,\n",
       "    307,\n",
       "    2531,\n",
       "    281,\n",
       "    257,\n",
       "    2120,\n",
       "    327,\n",
       "    332,\n",
       "    11075,\n",
       "    10225,\n",
       "    11,\n",
       "    1884,\n",
       "    257,\n",
       "    568,\n",
       "    35,\n",
       "    10225,\n",
       "    420,\n",
       "    8141,\n",
       "    365,\n",
       "    15329,\n",
       "    11,\n",
       "    51392],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 16,\n",
       "   'seek': 5560,\n",
       "   'start': 76.16,\n",
       "   'end': 80.72,\n",
       "   'text': ' then use Torch to convert it into a tensor. Now, we can run all kinds of computations on it,',\n",
       "   'tokens': [51392,\n",
       "    550,\n",
       "    764,\n",
       "    7160,\n",
       "    339,\n",
       "    281,\n",
       "    7620,\n",
       "    309,\n",
       "    666,\n",
       "    257,\n",
       "    40863,\n",
       "    13,\n",
       "    823,\n",
       "    11,\n",
       "    321,\n",
       "    393,\n",
       "    1190,\n",
       "    439,\n",
       "    3685,\n",
       "    295,\n",
       "    2807,\n",
       "    763,\n",
       "    322,\n",
       "    309,\n",
       "    11,\n",
       "    51620],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 17,\n",
       "   'seek': 5560,\n",
       "   'start': 80.72,\n",
       "   'end': 85.44,\n",
       "   'text': ' like we might convert all these integers into random floating points. We can also perform linear',\n",
       "   'tokens': [51620,\n",
       "    411,\n",
       "    321,\n",
       "    1062,\n",
       "    7620,\n",
       "    439,\n",
       "    613,\n",
       "    41674,\n",
       "    666,\n",
       "    4974,\n",
       "    12607,\n",
       "    2793,\n",
       "    13,\n",
       "    492,\n",
       "    393,\n",
       "    611,\n",
       "    2042,\n",
       "    8213,\n",
       "    51856],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 18,\n",
       "   'seek': 8544,\n",
       "   'start': 85.44,\n",
       "   'end': 90.32,\n",
       "   'text': ' algebra by taking multiple tensors and multiplying them together. What you came here to do, though,',\n",
       "   'tokens': [50364,\n",
       "    21989,\n",
       "    538,\n",
       "    1940,\n",
       "    3866,\n",
       "    10688,\n",
       "    830,\n",
       "    293,\n",
       "    30955,\n",
       "    552,\n",
       "    1214,\n",
       "    13,\n",
       "    708,\n",
       "    291,\n",
       "    1361,\n",
       "    510,\n",
       "    281,\n",
       "    360,\n",
       "    11,\n",
       "    1673,\n",
       "    11,\n",
       "    50608],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 19,\n",
       "   'seek': 8544,\n",
       "   'start': 90.32,\n",
       "   'end': 95.52,\n",
       "   'text': ' is build a deep neural network, like an image classifier. To handle that, we can define a new class',\n",
       "   'tokens': [50608,\n",
       "    307,\n",
       "    1322,\n",
       "    257,\n",
       "    2452,\n",
       "    18161,\n",
       "    3209,\n",
       "    11,\n",
       "    411,\n",
       "    364,\n",
       "    3256,\n",
       "    1508,\n",
       "    9902,\n",
       "    13,\n",
       "    1407,\n",
       "    4813,\n",
       "    300,\n",
       "    11,\n",
       "    321,\n",
       "    393,\n",
       "    6964,\n",
       "    257,\n",
       "    777,\n",
       "    1508,\n",
       "    50868],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 20,\n",
       "   'seek': 8544,\n",
       "   'start': 95.52,\n",
       "   'end': 100.32,\n",
       "   'text': ' that inherits from the neural network module class. Inside the constructor, we can build it out layer',\n",
       "   'tokens': [50868,\n",
       "    300,\n",
       "    9484,\n",
       "    1208,\n",
       "    490,\n",
       "    264,\n",
       "    18161,\n",
       "    3209,\n",
       "    10088,\n",
       "    1508,\n",
       "    13,\n",
       "    15123,\n",
       "    264,\n",
       "    47479,\n",
       "    11,\n",
       "    321,\n",
       "    393,\n",
       "    1322,\n",
       "    309,\n",
       "    484,\n",
       "    4583,\n",
       "    51108],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 21,\n",
       "   'seek': 8544,\n",
       "   'start': 100.32,\n",
       "   'end': 105.52,\n",
       "   'text': ' by layer. The flatten layer will take a multidimensional input, like an image, and convert it to one',\n",
       "   'tokens': [51108,\n",
       "    538,\n",
       "    4583,\n",
       "    13,\n",
       "    440,\n",
       "    24183,\n",
       "    4583,\n",
       "    486,\n",
       "    747,\n",
       "    257,\n",
       "    2120,\n",
       "    327,\n",
       "    332,\n",
       "    11075,\n",
       "    4846,\n",
       "    11,\n",
       "    411,\n",
       "    364,\n",
       "    3256,\n",
       "    11,\n",
       "    293,\n",
       "    7620,\n",
       "    309,\n",
       "    281,\n",
       "    472,\n",
       "    51368],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 22,\n",
       "   'seek': 8544,\n",
       "   'start': 105.52,\n",
       "   'end': 110.0,\n",
       "   'text': ' dimension. From there, sequential as use, you create a container of layers that the data will flow',\n",
       "   'tokens': [51368,\n",
       "    10139,\n",
       "    13,\n",
       "    3358,\n",
       "    456,\n",
       "    11,\n",
       "    42881,\n",
       "    382,\n",
       "    764,\n",
       "    11,\n",
       "    291,\n",
       "    1884,\n",
       "    257,\n",
       "    10129,\n",
       "    295,\n",
       "    7914,\n",
       "    300,\n",
       "    264,\n",
       "    1412,\n",
       "    486,\n",
       "    3095,\n",
       "    51592],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 23,\n",
       "   'seek': 8544,\n",
       "   'start': 110.0,\n",
       "   'end': 114.56,\n",
       "   'text': ' through. Each layer has multiple nodes, where each node is like its own mini statistical model,',\n",
       "   'tokens': [51592,\n",
       "    807,\n",
       "    13,\n",
       "    6947,\n",
       "    4583,\n",
       "    575,\n",
       "    3866,\n",
       "    13891,\n",
       "    11,\n",
       "    689,\n",
       "    1184,\n",
       "    9984,\n",
       "    307,\n",
       "    411,\n",
       "    1080,\n",
       "    1065,\n",
       "    8382,\n",
       "    22820,\n",
       "    2316,\n",
       "    11,\n",
       "    51820],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 24,\n",
       "   'seek': 11456,\n",
       "   'start': 114.56,\n",
       "   'end': 118.72,\n",
       "   'text': ' as each data point flows through it, it will try to guess the output, and gradually update a',\n",
       "   'tokens': [50364,\n",
       "    382,\n",
       "    1184,\n",
       "    1412,\n",
       "    935,\n",
       "    12867,\n",
       "    807,\n",
       "    309,\n",
       "    11,\n",
       "    309,\n",
       "    486,\n",
       "    853,\n",
       "    281,\n",
       "    2041,\n",
       "    264,\n",
       "    5598,\n",
       "    11,\n",
       "    293,\n",
       "    13145,\n",
       "    5623,\n",
       "    257,\n",
       "    50572],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 25,\n",
       "   'seek': 11456,\n",
       "   'start': 118.72,\n",
       "   'end': 123.44,\n",
       "   'text': ' mapping of weights to determine the importance of a given variable. Linear is a fully connected layer',\n",
       "   'tokens': [50572,\n",
       "    18350,\n",
       "    295,\n",
       "    17443,\n",
       "    281,\n",
       "    6997,\n",
       "    264,\n",
       "    7379,\n",
       "    295,\n",
       "    257,\n",
       "    2212,\n",
       "    7006,\n",
       "    13,\n",
       "    14670,\n",
       "    289,\n",
       "    307,\n",
       "    257,\n",
       "    4498,\n",
       "    4582,\n",
       "    4583,\n",
       "    50808],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 26,\n",
       "   'seek': 11456,\n",
       "   'start': 123.44,\n",
       "   'end': 129.84,\n",
       "   'text': ' that takes the flatten 28x28 image and transforms it to an output of 512. This layer is followed by a',\n",
       "   'tokens': [50808,\n",
       "    300,\n",
       "    2516,\n",
       "    264,\n",
       "    24183,\n",
       "    7562,\n",
       "    87,\n",
       "    11205,\n",
       "    3256,\n",
       "    293,\n",
       "    35592,\n",
       "    309,\n",
       "    281,\n",
       "    364,\n",
       "    5598,\n",
       "    295,\n",
       "    1025,\n",
       "    4762,\n",
       "    13,\n",
       "    639,\n",
       "    4583,\n",
       "    307,\n",
       "    6263,\n",
       "    538,\n",
       "    257,\n",
       "    51128],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 27,\n",
       "   'seek': 11456,\n",
       "   'start': 129.84,\n",
       "   'end': 134.24,\n",
       "   'text': ' non-linear activation function. When activated, it means that feature might be important,',\n",
       "   'tokens': [51128,\n",
       "    2107,\n",
       "    12,\n",
       "    28263,\n",
       "    24433,\n",
       "    2445,\n",
       "    13,\n",
       "    1133,\n",
       "    18157,\n",
       "    11,\n",
       "    309,\n",
       "    1355,\n",
       "    300,\n",
       "    4111,\n",
       "    1062,\n",
       "    312,\n",
       "    1021,\n",
       "    11,\n",
       "    51348],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 28,\n",
       "   'seek': 11456,\n",
       "   'start': 134.24,\n",
       "   'end': 138.88,\n",
       "   'text': ' and outputs the node, otherwise it just outputs zero. And finally, we finish with a fully connected',\n",
       "   'tokens': [51348,\n",
       "    293,\n",
       "    23930,\n",
       "    264,\n",
       "    9984,\n",
       "    11,\n",
       "    5911,\n",
       "    309,\n",
       "    445,\n",
       "    23930,\n",
       "    4018,\n",
       "    13,\n",
       "    400,\n",
       "    2721,\n",
       "    11,\n",
       "    321,\n",
       "    2413,\n",
       "    365,\n",
       "    257,\n",
       "    4498,\n",
       "    4582,\n",
       "    51580],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 29,\n",
       "   'seek': 11456,\n",
       "   'start': 138.88,\n",
       "   'end': 143.04,\n",
       "   'text': ' layer that outputs the 10 labels the model is trying to predict. With these pieces in place,',\n",
       "   'tokens': [51580,\n",
       "    4583,\n",
       "    300,\n",
       "    23930,\n",
       "    264,\n",
       "    1266,\n",
       "    16949,\n",
       "    264,\n",
       "    2316,\n",
       "    307,\n",
       "    1382,\n",
       "    281,\n",
       "    6069,\n",
       "    13,\n",
       "    2022,\n",
       "    613,\n",
       "    3755,\n",
       "    294,\n",
       "    1081,\n",
       "    11,\n",
       "    51788],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 30,\n",
       "   'seek': 14304,\n",
       "   'start': 143.04,\n",
       "   'end': 147.67999999999998,\n",
       "   'text': ' that next step is to define a forward method that describes the flow of data, and now instantiate',\n",
       "   'tokens': [50364,\n",
       "    300,\n",
       "    958,\n",
       "    1823,\n",
       "    307,\n",
       "    281,\n",
       "    6964,\n",
       "    257,\n",
       "    2128,\n",
       "    3170,\n",
       "    300,\n",
       "    15626,\n",
       "    264,\n",
       "    3095,\n",
       "    295,\n",
       "    1412,\n",
       "    11,\n",
       "    293,\n",
       "    586,\n",
       "    9836,\n",
       "    13024,\n",
       "    50596],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14715951139276678,\n",
       "   'compression_ratio': 1.58008658008658,\n",
       "   'no_speech_prob': 0.00043724410352297127},\n",
       "  {'id': 31,\n",
       "   'seek': 14304,\n",
       "   'start': 147.67999999999998,\n",
       "   'end': 152.64,\n",
       "   'text': ' the model to a GPU, and pass its input data. This will automatically call its forward method,',\n",
       "   'tokens': [50596,\n",
       "    264,\n",
       "    2316,\n",
       "    281,\n",
       "    257,\n",
       "    18407,\n",
       "    11,\n",
       "    293,\n",
       "    1320,\n",
       "    1080,\n",
       "    4846,\n",
       "    1412,\n",
       "    13,\n",
       "    639,\n",
       "    486,\n",
       "    6772,\n",
       "    818,\n",
       "    1080,\n",
       "    2128,\n",
       "    3170,\n",
       "    11,\n",
       "    50844],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14715951139276678,\n",
       "   'compression_ratio': 1.58008658008658,\n",
       "   'no_speech_prob': 0.00043724410352297127},\n",
       "  {'id': 32,\n",
       "   'seek': 14304,\n",
       "   'start': 152.64,\n",
       "   'end': 157.04,\n",
       "   'text': ' for training and prediction. Congratulations, you just built a neural network. This has been',\n",
       "   'tokens': [50844,\n",
       "    337,\n",
       "    3097,\n",
       "    293,\n",
       "    17630,\n",
       "    13,\n",
       "    9694,\n",
       "    11,\n",
       "    291,\n",
       "    445,\n",
       "    3094,\n",
       "    257,\n",
       "    18161,\n",
       "    3209,\n",
       "    13,\n",
       "    639,\n",
       "    575,\n",
       "    668,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14715951139276678,\n",
       "   'compression_ratio': 1.58008658008658,\n",
       "   'no_speech_prob': 0.00043724410352297127},\n",
       "  {'id': 33,\n",
       "   'seek': 14304,\n",
       "   'start': 157.04,\n",
       "   'end': 161.84,\n",
       "   'text': ' PyTorch in 100 seconds. Thanks for watching, and I will see you in the next one.',\n",
       "   'tokens': [51064,\n",
       "    9953,\n",
       "    51,\n",
       "    284,\n",
       "    339,\n",
       "    294,\n",
       "    2319,\n",
       "    3949,\n",
       "    13,\n",
       "    2561,\n",
       "    337,\n",
       "    1976,\n",
       "    11,\n",
       "    293,\n",
       "    286,\n",
       "    486,\n",
       "    536,\n",
       "    291,\n",
       "    294,\n",
       "    264,\n",
       "    958,\n",
       "    472,\n",
       "    13,\n",
       "    51304],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14715951139276678,\n",
       "   'compression_ratio': 1.58008658008658,\n",
       "   'no_speech_prob': 0.00043724410352297127}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3d77c164-627c-49ce-b04a-d8f3e2e3d2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.56</td>\n",
       "      <td>The Pi Torch, an open-source deep learning framework used to build some of the world's most</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.56</td>\n",
       "      <td>9.76</td>\n",
       "      <td>famous artificial intelligence products. It was created at the Meta AI Research Lab in 2016,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>but is actually derived from the Lua-based torch library that dates back to 2002.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14.48</td>\n",
       "      <td>18.48</td>\n",
       "      <td>Fundamentally, it's a library for programming with tensors, which are basically just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>18.48</td>\n",
       "      <td>22.96</td>\n",
       "      <td>multidimensional arrays that represent data and parameters in deep neural networks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>22.96</td>\n",
       "      <td>27.04</td>\n",
       "      <td>Sounds complicated, but its focus on usability will have you training machine learning models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>27.04</td>\n",
       "      <td>31.12</td>\n",
       "      <td>with just a few lines of Python. In addition, it facilitates high-performance parallel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>31.12</td>\n",
       "      <td>36.40</td>\n",
       "      <td>computing on a GPU, thanks to Nvidia's CUDA platform. Developers love prototyping with it,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>36.40</td>\n",
       "      <td>41.04</td>\n",
       "      <td>because it supports a dynamic computation graph, allowing models to be optimized at runtime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>41.04</td>\n",
       "      <td>46.32</td>\n",
       "      <td>It does this by constructing a directed A-cyclic graph consisting of functions that keeps track of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>46.32</td>\n",
       "      <td>51.04</td>\n",
       "      <td>all the executed operations on the tensors, allowing you to change the shape, size, and operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>51.04</td>\n",
       "      <td>55.60</td>\n",
       "      <td>after every iteration if needed. Pi Torch has been used to train models for computer vision AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>55.68</td>\n",
       "      <td>60.56</td>\n",
       "      <td>like Tesla Autopilot, image generators like stable diffusion, and speech recognition models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>60.56</td>\n",
       "      <td>65.60</td>\n",
       "      <td>like OpenAI Whisper, just to name a few. To get started, install Pi Torch and optionally CUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>65.60</td>\n",
       "      <td>70.56</td>\n",
       "      <td>if you want to accelerate computing on your GPU. Now, import it into a Python file or notebook,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>70.56</td>\n",
       "      <td>76.16</td>\n",
       "      <td>like I mentioned, a tensor is similar to a multidimensional array, create a 2D array or matrix with Python,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>76.16</td>\n",
       "      <td>80.72</td>\n",
       "      <td>then use Torch to convert it into a tensor. Now, we can run all kinds of computations on it,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>80.72</td>\n",
       "      <td>85.44</td>\n",
       "      <td>like we might convert all these integers into random floating points. We can also perform linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>85.44</td>\n",
       "      <td>90.32</td>\n",
       "      <td>algebra by taking multiple tensors and multiplying them together. What you came here to do, though,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>90.32</td>\n",
       "      <td>95.52</td>\n",
       "      <td>is build a deep neural network, like an image classifier. To handle that, we can define a new class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>95.52</td>\n",
       "      <td>100.32</td>\n",
       "      <td>that inherits from the neural network module class. Inside the constructor, we can build it out layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>100.32</td>\n",
       "      <td>105.52</td>\n",
       "      <td>by layer. The flatten layer will take a multidimensional input, like an image, and convert it to one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>105.52</td>\n",
       "      <td>110.00</td>\n",
       "      <td>dimension. From there, sequential as use, you create a container of layers that the data will flow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>110.00</td>\n",
       "      <td>114.56</td>\n",
       "      <td>through. Each layer has multiple nodes, where each node is like its own mini statistical model,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>114.56</td>\n",
       "      <td>118.72</td>\n",
       "      <td>as each data point flows through it, it will try to guess the output, and gradually update a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>118.72</td>\n",
       "      <td>123.44</td>\n",
       "      <td>mapping of weights to determine the importance of a given variable. Linear is a fully connected layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>123.44</td>\n",
       "      <td>129.84</td>\n",
       "      <td>that takes the flatten 28x28 image and transforms it to an output of 512. This layer is followed by a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>129.84</td>\n",
       "      <td>134.24</td>\n",
       "      <td>non-linear activation function. When activated, it means that feature might be important,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>134.24</td>\n",
       "      <td>138.88</td>\n",
       "      <td>and outputs the node, otherwise it just outputs zero. And finally, we finish with a fully connected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>138.88</td>\n",
       "      <td>143.04</td>\n",
       "      <td>layer that outputs the 10 labels the model is trying to predict. With these pieces in place,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>143.04</td>\n",
       "      <td>147.68</td>\n",
       "      <td>that next step is to define a forward method that describes the flow of data, and now instantiate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>147.68</td>\n",
       "      <td>152.64</td>\n",
       "      <td>the model to a GPU, and pass its input data. This will automatically call its forward method,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>152.64</td>\n",
       "      <td>157.04</td>\n",
       "      <td>for training and prediction. Congratulations, you just built a neural network. This has been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>157.04</td>\n",
       "      <td>161.84</td>\n",
       "      <td>PyTorch in 100 seconds. Thanks for watching, and I will see you in the next one.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   start     end  \\\n",
       "0    0    0.00    4.56   \n",
       "1    1    4.56    9.76   \n",
       "2    2    9.76   14.48   \n",
       "3    3   14.48   18.48   \n",
       "4    4   18.48   22.96   \n",
       "5    5   22.96   27.04   \n",
       "6    6   27.04   31.12   \n",
       "7    7   31.12   36.40   \n",
       "8    8   36.40   41.04   \n",
       "9    9   41.04   46.32   \n",
       "10  10   46.32   51.04   \n",
       "11  11   51.04   55.60   \n",
       "12  12   55.68   60.56   \n",
       "13  13   60.56   65.60   \n",
       "14  14   65.60   70.56   \n",
       "15  15   70.56   76.16   \n",
       "16  16   76.16   80.72   \n",
       "17  17   80.72   85.44   \n",
       "18  18   85.44   90.32   \n",
       "19  19   90.32   95.52   \n",
       "20  20   95.52  100.32   \n",
       "21  21  100.32  105.52   \n",
       "22  22  105.52  110.00   \n",
       "23  23  110.00  114.56   \n",
       "24  24  114.56  118.72   \n",
       "25  25  118.72  123.44   \n",
       "26  26  123.44  129.84   \n",
       "27  27  129.84  134.24   \n",
       "28  28  134.24  138.88   \n",
       "29  29  138.88  143.04   \n",
       "30  30  143.04  147.68   \n",
       "31  31  147.68  152.64   \n",
       "32  32  152.64  157.04   \n",
       "33  33  157.04  161.84   \n",
       "\n",
       "                                                                                                            text  \n",
       "0                    The Pi Torch, an open-source deep learning framework used to build some of the world's most  \n",
       "1                   famous artificial intelligence products. It was created at the Meta AI Research Lab in 2016,  \n",
       "2                              but is actually derived from the Lua-based torch library that dates back to 2002.  \n",
       "3                           Fundamentally, it's a library for programming with tensors, which are basically just  \n",
       "4                            multidimensional arrays that represent data and parameters in deep neural networks.  \n",
       "5                  Sounds complicated, but its focus on usability will have you training machine learning models  \n",
       "6                         with just a few lines of Python. In addition, it facilitates high-performance parallel  \n",
       "7                     computing on a GPU, thanks to Nvidia's CUDA platform. Developers love prototyping with it,  \n",
       "8                   because it supports a dynamic computation graph, allowing models to be optimized at runtime.  \n",
       "9             It does this by constructing a directed A-cyclic graph consisting of functions that keeps track of  \n",
       "10            all the executed operations on the tensors, allowing you to change the shape, size, and operations  \n",
       "11                after every iteration if needed. Pi Torch has been used to train models for computer vision AI  \n",
       "12                   like Tesla Autopilot, image generators like stable diffusion, and speech recognition models  \n",
       "13                 like OpenAI Whisper, just to name a few. To get started, install Pi Torch and optionally CUDA  \n",
       "14               if you want to accelerate computing on your GPU. Now, import it into a Python file or notebook,  \n",
       "15   like I mentioned, a tensor is similar to a multidimensional array, create a 2D array or matrix with Python,  \n",
       "16                  then use Torch to convert it into a tensor. Now, we can run all kinds of computations on it,  \n",
       "17              like we might convert all these integers into random floating points. We can also perform linear  \n",
       "18           algebra by taking multiple tensors and multiplying them together. What you came here to do, though,  \n",
       "19           is build a deep neural network, like an image classifier. To handle that, we can define a new class  \n",
       "20         that inherits from the neural network module class. Inside the constructor, we can build it out layer  \n",
       "21          by layer. The flatten layer will take a multidimensional input, like an image, and convert it to one  \n",
       "22            dimension. From there, sequential as use, you create a container of layers that the data will flow  \n",
       "23               through. Each layer has multiple nodes, where each node is like its own mini statistical model,  \n",
       "24                  as each data point flows through it, it will try to guess the output, and gradually update a  \n",
       "25         mapping of weights to determine the importance of a given variable. Linear is a fully connected layer  \n",
       "26         that takes the flatten 28x28 image and transforms it to an output of 512. This layer is followed by a  \n",
       "27                     non-linear activation function. When activated, it means that feature might be important,  \n",
       "28           and outputs the node, otherwise it just outputs zero. And finally, we finish with a fully connected  \n",
       "29                  layer that outputs the 10 labels the model is trying to predict. With these pieces in place,  \n",
       "30             that next step is to define a forward method that describes the flow of data, and now instantiate  \n",
       "31                 the model to a GPU, and pass its input data. This will automatically call its forward method,  \n",
       "32                  for training and prediction. Congratulations, you just built a neural network. This has been  \n",
       "33                              PyTorch in 100 seconds. Thanks for watching, and I will see you in the next one.  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 1000)\n",
    "text_segment = pd.DataFrame(transcription['segments'], columns=['id','start', 'end', 'text'])\n",
    "text_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f151ad6-492c-4cc4-826c-68fdfeb0a882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fulltext(model_output):\n",
    "    return model_output['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bc5bda0-16fd-4a0c-b918-9230af901d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_text = get_fulltext(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49c0072f-1f06-4e00-b923-89fea06f4c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_srt(text, name):\n",
    "    with open(f\"{name}.srt\", \"w\") as f:\n",
    "        f.write(text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c83588f-9702-4021-9664-775f5181c075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_srt(full_text, 'pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef116f-cce6-4be2-942b-87f87e187d4b",
   "metadata": {},
   "source": [
    "#### a hacky way to get the time-stamp\n",
    "---\n",
    "- Assumption : We all have a constant speech rate. Some speak fast. Some speak slow.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7681ff3f-d26a-47f4-8c7e-ff27aad55bf8",
   "metadata": {},
   "source": [
    "- Geeting the indices where the world `CUDA` is found in the entire transcription text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f2735f07-6af9-46fb-9d41-36037306f7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[657, 661], [1276, 1280]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_findings = [[i.start(), i.end()] for i in re.finditer('CUDA', transcription['text'])]\n",
    "word_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9e41d7e6-c4e9-4a7f-8e54-f1d3f759fa90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_segment.iloc[0].text.find('CUDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d94525ad-9702-48df-922d-3207a9d1c074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MKBHD is not found in the transcription\n",
      "[7, 13, 33, 7, 14, 31]\n"
     ]
    }
   ],
   "source": [
    "id_len = len(text_segment)\n",
    "words_to_find = ['CUDA', 'PyTorch', 'GPU', 'MKBHD']\n",
    "index = []\n",
    "place_holder = []\n",
    "\n",
    "for word in words_to_find:\n",
    "    for ids in range(id_len):\n",
    "        check = text_segment.iloc[ids].text.find(word)\n",
    "        if check >= 0:\n",
    "            index.append(ids)\n",
    "    if [i.start() for i in re.finditer(word, transcription['text'])] == []:\n",
    "        print(f' {word} is not found in the transcription')\n",
    "    \n",
    "    \n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "301d72d9-e08e-498f-9775-18148e52d802",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" The Pi Torch, an open-source deep learning framework used to build some of the world's most famous artificial intelligence products. It was created at the Meta AI Research Lab in 2016, but is actually derived from the Lua-based torch library that dates back to 2002. Fundamentally, it's a library for programming with tensors, which are basically just multidimensional arrays that represent data and parameters in deep neural networks. Sounds complicated, but its focus on usability will have you training machine learning models with just a few lines of Python. In addition, it facilitates high-performance parallel computing on a GPU, thanks to Nvidia's CUDA platform. Developers love prototyping with it, because it supports a dynamic computation graph, allowing models to be optimized at runtime. It does this by constructing a directed A-cyclic graph consisting of functions that keeps track of all the executed operations on the tensors, allowing you to change the shape, size, and operations after every iteration if needed. Pi Torch has been used to train models for computer vision AI like Tesla Autopilot, image generators like stable diffusion, and speech recognition models like OpenAI Whisper, just to name a few. To get started, install Pi Torch and optionally CUDA if you want to accelerate computing on your GPU. Now, import it into a Python file or notebook, like I mentioned, a tensor is similar to a multidimensional array, create a 2D array or matrix with Python, then use Torch to convert it into a tensor. Now, we can run all kinds of computations on it, like we might convert all these integers into random floating points. We can also perform linear algebra by taking multiple tensors and multiplying them together. What you came here to do, though, is build a deep neural network, like an image classifier. To handle that, we can define a new class that inherits from the neural network module class. Inside the constructor, we can build it out layer by layer. The flatten layer will take a multidimensional input, like an image, and convert it to one dimension. From there, sequential as use, you create a container of layers that the data will flow through. Each layer has multiple nodes, where each node is like its own mini statistical model, as each data point flows through it, it will try to guess the output, and gradually update a mapping of weights to determine the importance of a given variable. Linear is a fully connected layer that takes the flatten 28x28 image and transforms it to an output of 512. This layer is followed by a non-linear activation function. When activated, it means that feature might be important, and outputs the node, otherwise it just outputs zero. And finally, we finish with a fully connected layer that outputs the 10 labels the model is trying to predict. With these pieces in place, that next step is to define a forward method that describes the flow of data, and now instantiate the model to a GPU, and pass its input data. This will automatically call its forward method, for training and prediction. Congratulations, you just built a neural network. This has been PyTorch in 100 seconds. Thanks for watching, and I will see you in the next one.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 4.5600000000000005,\n",
       "   'text': \" The Pi Torch, an open-source deep learning framework used to build some of the world's most\",\n",
       "   'tokens': [50364,\n",
       "    440,\n",
       "    17741,\n",
       "    7160,\n",
       "    339,\n",
       "    11,\n",
       "    364,\n",
       "    1269,\n",
       "    12,\n",
       "    41676,\n",
       "    2452,\n",
       "    2539,\n",
       "    8388,\n",
       "    1143,\n",
       "    281,\n",
       "    1322,\n",
       "    512,\n",
       "    295,\n",
       "    264,\n",
       "    1002,\n",
       "    311,\n",
       "    881,\n",
       "    50592],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 4.5600000000000005,\n",
       "   'end': 9.76,\n",
       "   'text': ' famous artificial intelligence products. It was created at the Meta AI Research Lab in 2016,',\n",
       "   'tokens': [50592,\n",
       "    4618,\n",
       "    11677,\n",
       "    7599,\n",
       "    3383,\n",
       "    13,\n",
       "    467,\n",
       "    390,\n",
       "    2942,\n",
       "    412,\n",
       "    264,\n",
       "    6377,\n",
       "    64,\n",
       "    7318,\n",
       "    10303,\n",
       "    10137,\n",
       "    294,\n",
       "    6549,\n",
       "    11,\n",
       "    50852],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 9.76,\n",
       "   'end': 14.48,\n",
       "   'text': ' but is actually derived from the Lua-based torch library that dates back to 2002.',\n",
       "   'tokens': [50852,\n",
       "    457,\n",
       "    307,\n",
       "    767,\n",
       "    18949,\n",
       "    490,\n",
       "    264,\n",
       "    441,\n",
       "    4398,\n",
       "    12,\n",
       "    6032,\n",
       "    27822,\n",
       "    6405,\n",
       "    300,\n",
       "    11691,\n",
       "    646,\n",
       "    281,\n",
       "    17822,\n",
       "    13,\n",
       "    51088],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': 14.48,\n",
       "   'end': 18.48,\n",
       "   'text': \" Fundamentally, it's a library for programming with tensors, which are basically just\",\n",
       "   'tokens': [51088,\n",
       "    13493,\n",
       "    2466,\n",
       "    379,\n",
       "    11,\n",
       "    309,\n",
       "    311,\n",
       "    257,\n",
       "    6405,\n",
       "    337,\n",
       "    9410,\n",
       "    365,\n",
       "    10688,\n",
       "    830,\n",
       "    11,\n",
       "    597,\n",
       "    366,\n",
       "    1936,\n",
       "    445,\n",
       "    51288],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 4,\n",
       "   'seek': 0,\n",
       "   'start': 18.48,\n",
       "   'end': 22.96,\n",
       "   'text': ' multidimensional arrays that represent data and parameters in deep neural networks.',\n",
       "   'tokens': [51288,\n",
       "    2120,\n",
       "    327,\n",
       "    332,\n",
       "    11075,\n",
       "    41011,\n",
       "    300,\n",
       "    2906,\n",
       "    1412,\n",
       "    293,\n",
       "    9834,\n",
       "    294,\n",
       "    2452,\n",
       "    18161,\n",
       "    9590,\n",
       "    13,\n",
       "    51512],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 5,\n",
       "   'seek': 0,\n",
       "   'start': 22.96,\n",
       "   'end': 27.04,\n",
       "   'text': ' Sounds complicated, but its focus on usability will have you training machine learning models',\n",
       "   'tokens': [51512,\n",
       "    14576,\n",
       "    6179,\n",
       "    11,\n",
       "    457,\n",
       "    1080,\n",
       "    1879,\n",
       "    322,\n",
       "    46878,\n",
       "    486,\n",
       "    362,\n",
       "    291,\n",
       "    3097,\n",
       "    3479,\n",
       "    2539,\n",
       "    5245,\n",
       "    51716],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1372630495985015,\n",
       "   'compression_ratio': 1.5697329376854599,\n",
       "   'no_speech_prob': 0.14381708204746246},\n",
       "  {'id': 6,\n",
       "   'seek': 2704,\n",
       "   'start': 27.04,\n",
       "   'end': 31.119999999999997,\n",
       "   'text': ' with just a few lines of Python. In addition, it facilitates high-performance parallel',\n",
       "   'tokens': [50364,\n",
       "    365,\n",
       "    445,\n",
       "    257,\n",
       "    1326,\n",
       "    3876,\n",
       "    295,\n",
       "    15329,\n",
       "    13,\n",
       "    682,\n",
       "    4500,\n",
       "    11,\n",
       "    309,\n",
       "    10217,\n",
       "    30035,\n",
       "    1090,\n",
       "    12,\n",
       "    50242,\n",
       "    8952,\n",
       "    50568],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 7,\n",
       "   'seek': 2704,\n",
       "   'start': 31.119999999999997,\n",
       "   'end': 36.4,\n",
       "   'text': \" computing on a GPU, thanks to Nvidia's CUDA platform. Developers love prototyping with it,\",\n",
       "   'tokens': [50568,\n",
       "    15866,\n",
       "    322,\n",
       "    257,\n",
       "    18407,\n",
       "    11,\n",
       "    3231,\n",
       "    281,\n",
       "    46284,\n",
       "    311,\n",
       "    29777,\n",
       "    7509,\n",
       "    3663,\n",
       "    13,\n",
       "    11442,\n",
       "    433,\n",
       "    959,\n",
       "    46219,\n",
       "    3381,\n",
       "    365,\n",
       "    309,\n",
       "    11,\n",
       "    50832],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 8,\n",
       "   'seek': 2704,\n",
       "   'start': 36.4,\n",
       "   'end': 41.04,\n",
       "   'text': ' because it supports a dynamic computation graph, allowing models to be optimized at runtime.',\n",
       "   'tokens': [50832,\n",
       "    570,\n",
       "    309,\n",
       "    9346,\n",
       "    257,\n",
       "    8546,\n",
       "    24903,\n",
       "    4295,\n",
       "    11,\n",
       "    8293,\n",
       "    5245,\n",
       "    281,\n",
       "    312,\n",
       "    26941,\n",
       "    412,\n",
       "    34474,\n",
       "    13,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 9,\n",
       "   'seek': 2704,\n",
       "   'start': 41.04,\n",
       "   'end': 46.32,\n",
       "   'text': ' It does this by constructing a directed A-cyclic graph consisting of functions that keeps track of',\n",
       "   'tokens': [51064,\n",
       "    467,\n",
       "    775,\n",
       "    341,\n",
       "    538,\n",
       "    39969,\n",
       "    257,\n",
       "    12898,\n",
       "    316,\n",
       "    12,\n",
       "    1344,\n",
       "    66,\n",
       "    1050,\n",
       "    4295,\n",
       "    33921,\n",
       "    295,\n",
       "    6828,\n",
       "    300,\n",
       "    5965,\n",
       "    2837,\n",
       "    295,\n",
       "    51328],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 10,\n",
       "   'seek': 2704,\n",
       "   'start': 46.32,\n",
       "   'end': 51.04,\n",
       "   'text': ' all the executed operations on the tensors, allowing you to change the shape, size, and operations',\n",
       "   'tokens': [51328,\n",
       "    439,\n",
       "    264,\n",
       "    17577,\n",
       "    7705,\n",
       "    322,\n",
       "    264,\n",
       "    10688,\n",
       "    830,\n",
       "    11,\n",
       "    8293,\n",
       "    291,\n",
       "    281,\n",
       "    1319,\n",
       "    264,\n",
       "    3909,\n",
       "    11,\n",
       "    2744,\n",
       "    11,\n",
       "    293,\n",
       "    7705,\n",
       "    51564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 11,\n",
       "   'seek': 2704,\n",
       "   'start': 51.04,\n",
       "   'end': 55.6,\n",
       "   'text': ' after every iteration if needed. Pi Torch has been used to train models for computer vision AI',\n",
       "   'tokens': [51564,\n",
       "    934,\n",
       "    633,\n",
       "    24784,\n",
       "    498,\n",
       "    2978,\n",
       "    13,\n",
       "    17741,\n",
       "    7160,\n",
       "    339,\n",
       "    575,\n",
       "    668,\n",
       "    1143,\n",
       "    281,\n",
       "    3847,\n",
       "    5245,\n",
       "    337,\n",
       "    3820,\n",
       "    5201,\n",
       "    7318,\n",
       "    51792],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10508832335472107,\n",
       "   'compression_ratio': 1.6271676300578035,\n",
       "   'no_speech_prob': 0.010165199637413025},\n",
       "  {'id': 12,\n",
       "   'seek': 5560,\n",
       "   'start': 55.68,\n",
       "   'end': 60.56,\n",
       "   'text': ' like Tesla Autopilot, image generators like stable diffusion, and speech recognition models',\n",
       "   'tokens': [50368,\n",
       "    411,\n",
       "    13666,\n",
       "    6049,\n",
       "    404,\n",
       "    31516,\n",
       "    11,\n",
       "    3256,\n",
       "    38662,\n",
       "    411,\n",
       "    8351,\n",
       "    25242,\n",
       "    11,\n",
       "    293,\n",
       "    6218,\n",
       "    11150,\n",
       "    5245,\n",
       "    50612],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 13,\n",
       "   'seek': 5560,\n",
       "   'start': 60.56,\n",
       "   'end': 65.6,\n",
       "   'text': ' like OpenAI Whisper, just to name a few. To get started, install Pi Torch and optionally CUDA',\n",
       "   'tokens': [50612,\n",
       "    411,\n",
       "    7238,\n",
       "    48698,\n",
       "    41132,\n",
       "    610,\n",
       "    11,\n",
       "    445,\n",
       "    281,\n",
       "    1315,\n",
       "    257,\n",
       "    1326,\n",
       "    13,\n",
       "    1407,\n",
       "    483,\n",
       "    1409,\n",
       "    11,\n",
       "    3625,\n",
       "    17741,\n",
       "    7160,\n",
       "    339,\n",
       "    293,\n",
       "    3614,\n",
       "    379,\n",
       "    29777,\n",
       "    7509,\n",
       "    50864],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 14,\n",
       "   'seek': 5560,\n",
       "   'start': 65.6,\n",
       "   'end': 70.56,\n",
       "   'text': ' if you want to accelerate computing on your GPU. Now, import it into a Python file or notebook,',\n",
       "   'tokens': [50864,\n",
       "    498,\n",
       "    291,\n",
       "    528,\n",
       "    281,\n",
       "    21341,\n",
       "    15866,\n",
       "    322,\n",
       "    428,\n",
       "    18407,\n",
       "    13,\n",
       "    823,\n",
       "    11,\n",
       "    974,\n",
       "    309,\n",
       "    666,\n",
       "    257,\n",
       "    15329,\n",
       "    3991,\n",
       "    420,\n",
       "    21060,\n",
       "    11,\n",
       "    51112],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 15,\n",
       "   'seek': 5560,\n",
       "   'start': 70.56,\n",
       "   'end': 76.16,\n",
       "   'text': ' like I mentioned, a tensor is similar to a multidimensional array, create a 2D array or matrix with Python,',\n",
       "   'tokens': [51112,\n",
       "    411,\n",
       "    286,\n",
       "    2835,\n",
       "    11,\n",
       "    257,\n",
       "    40863,\n",
       "    307,\n",
       "    2531,\n",
       "    281,\n",
       "    257,\n",
       "    2120,\n",
       "    327,\n",
       "    332,\n",
       "    11075,\n",
       "    10225,\n",
       "    11,\n",
       "    1884,\n",
       "    257,\n",
       "    568,\n",
       "    35,\n",
       "    10225,\n",
       "    420,\n",
       "    8141,\n",
       "    365,\n",
       "    15329,\n",
       "    11,\n",
       "    51392],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 16,\n",
       "   'seek': 5560,\n",
       "   'start': 76.16,\n",
       "   'end': 80.72,\n",
       "   'text': ' then use Torch to convert it into a tensor. Now, we can run all kinds of computations on it,',\n",
       "   'tokens': [51392,\n",
       "    550,\n",
       "    764,\n",
       "    7160,\n",
       "    339,\n",
       "    281,\n",
       "    7620,\n",
       "    309,\n",
       "    666,\n",
       "    257,\n",
       "    40863,\n",
       "    13,\n",
       "    823,\n",
       "    11,\n",
       "    321,\n",
       "    393,\n",
       "    1190,\n",
       "    439,\n",
       "    3685,\n",
       "    295,\n",
       "    2807,\n",
       "    763,\n",
       "    322,\n",
       "    309,\n",
       "    11,\n",
       "    51620],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 17,\n",
       "   'seek': 5560,\n",
       "   'start': 80.72,\n",
       "   'end': 85.44,\n",
       "   'text': ' like we might convert all these integers into random floating points. We can also perform linear',\n",
       "   'tokens': [51620,\n",
       "    411,\n",
       "    321,\n",
       "    1062,\n",
       "    7620,\n",
       "    439,\n",
       "    613,\n",
       "    41674,\n",
       "    666,\n",
       "    4974,\n",
       "    12607,\n",
       "    2793,\n",
       "    13,\n",
       "    492,\n",
       "    393,\n",
       "    611,\n",
       "    2042,\n",
       "    8213,\n",
       "    51856],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.10961352528392018,\n",
       "   'compression_ratio': 1.6685878962536023,\n",
       "   'no_speech_prob': 0.01223739143460989},\n",
       "  {'id': 18,\n",
       "   'seek': 8544,\n",
       "   'start': 85.44,\n",
       "   'end': 90.32,\n",
       "   'text': ' algebra by taking multiple tensors and multiplying them together. What you came here to do, though,',\n",
       "   'tokens': [50364,\n",
       "    21989,\n",
       "    538,\n",
       "    1940,\n",
       "    3866,\n",
       "    10688,\n",
       "    830,\n",
       "    293,\n",
       "    30955,\n",
       "    552,\n",
       "    1214,\n",
       "    13,\n",
       "    708,\n",
       "    291,\n",
       "    1361,\n",
       "    510,\n",
       "    281,\n",
       "    360,\n",
       "    11,\n",
       "    1673,\n",
       "    11,\n",
       "    50608],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 19,\n",
       "   'seek': 8544,\n",
       "   'start': 90.32,\n",
       "   'end': 95.52,\n",
       "   'text': ' is build a deep neural network, like an image classifier. To handle that, we can define a new class',\n",
       "   'tokens': [50608,\n",
       "    307,\n",
       "    1322,\n",
       "    257,\n",
       "    2452,\n",
       "    18161,\n",
       "    3209,\n",
       "    11,\n",
       "    411,\n",
       "    364,\n",
       "    3256,\n",
       "    1508,\n",
       "    9902,\n",
       "    13,\n",
       "    1407,\n",
       "    4813,\n",
       "    300,\n",
       "    11,\n",
       "    321,\n",
       "    393,\n",
       "    6964,\n",
       "    257,\n",
       "    777,\n",
       "    1508,\n",
       "    50868],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 20,\n",
       "   'seek': 8544,\n",
       "   'start': 95.52,\n",
       "   'end': 100.32,\n",
       "   'text': ' that inherits from the neural network module class. Inside the constructor, we can build it out layer',\n",
       "   'tokens': [50868,\n",
       "    300,\n",
       "    9484,\n",
       "    1208,\n",
       "    490,\n",
       "    264,\n",
       "    18161,\n",
       "    3209,\n",
       "    10088,\n",
       "    1508,\n",
       "    13,\n",
       "    15123,\n",
       "    264,\n",
       "    47479,\n",
       "    11,\n",
       "    321,\n",
       "    393,\n",
       "    1322,\n",
       "    309,\n",
       "    484,\n",
       "    4583,\n",
       "    51108],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 21,\n",
       "   'seek': 8544,\n",
       "   'start': 100.32,\n",
       "   'end': 105.52,\n",
       "   'text': ' by layer. The flatten layer will take a multidimensional input, like an image, and convert it to one',\n",
       "   'tokens': [51108,\n",
       "    538,\n",
       "    4583,\n",
       "    13,\n",
       "    440,\n",
       "    24183,\n",
       "    4583,\n",
       "    486,\n",
       "    747,\n",
       "    257,\n",
       "    2120,\n",
       "    327,\n",
       "    332,\n",
       "    11075,\n",
       "    4846,\n",
       "    11,\n",
       "    411,\n",
       "    364,\n",
       "    3256,\n",
       "    11,\n",
       "    293,\n",
       "    7620,\n",
       "    309,\n",
       "    281,\n",
       "    472,\n",
       "    51368],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 22,\n",
       "   'seek': 8544,\n",
       "   'start': 105.52,\n",
       "   'end': 110.0,\n",
       "   'text': ' dimension. From there, sequential as use, you create a container of layers that the data will flow',\n",
       "   'tokens': [51368,\n",
       "    10139,\n",
       "    13,\n",
       "    3358,\n",
       "    456,\n",
       "    11,\n",
       "    42881,\n",
       "    382,\n",
       "    764,\n",
       "    11,\n",
       "    291,\n",
       "    1884,\n",
       "    257,\n",
       "    10129,\n",
       "    295,\n",
       "    7914,\n",
       "    300,\n",
       "    264,\n",
       "    1412,\n",
       "    486,\n",
       "    3095,\n",
       "    51592],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 23,\n",
       "   'seek': 8544,\n",
       "   'start': 110.0,\n",
       "   'end': 114.56,\n",
       "   'text': ' through. Each layer has multiple nodes, where each node is like its own mini statistical model,',\n",
       "   'tokens': [51592,\n",
       "    807,\n",
       "    13,\n",
       "    6947,\n",
       "    4583,\n",
       "    575,\n",
       "    3866,\n",
       "    13891,\n",
       "    11,\n",
       "    689,\n",
       "    1184,\n",
       "    9984,\n",
       "    307,\n",
       "    411,\n",
       "    1080,\n",
       "    1065,\n",
       "    8382,\n",
       "    22820,\n",
       "    2316,\n",
       "    11,\n",
       "    51820],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.09267334256853377,\n",
       "   'compression_ratio': 1.8201219512195121,\n",
       "   'no_speech_prob': 0.0033240565098822117},\n",
       "  {'id': 24,\n",
       "   'seek': 11456,\n",
       "   'start': 114.56,\n",
       "   'end': 118.72,\n",
       "   'text': ' as each data point flows through it, it will try to guess the output, and gradually update a',\n",
       "   'tokens': [50364,\n",
       "    382,\n",
       "    1184,\n",
       "    1412,\n",
       "    935,\n",
       "    12867,\n",
       "    807,\n",
       "    309,\n",
       "    11,\n",
       "    309,\n",
       "    486,\n",
       "    853,\n",
       "    281,\n",
       "    2041,\n",
       "    264,\n",
       "    5598,\n",
       "    11,\n",
       "    293,\n",
       "    13145,\n",
       "    5623,\n",
       "    257,\n",
       "    50572],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 25,\n",
       "   'seek': 11456,\n",
       "   'start': 118.72,\n",
       "   'end': 123.44,\n",
       "   'text': ' mapping of weights to determine the importance of a given variable. Linear is a fully connected layer',\n",
       "   'tokens': [50572,\n",
       "    18350,\n",
       "    295,\n",
       "    17443,\n",
       "    281,\n",
       "    6997,\n",
       "    264,\n",
       "    7379,\n",
       "    295,\n",
       "    257,\n",
       "    2212,\n",
       "    7006,\n",
       "    13,\n",
       "    14670,\n",
       "    289,\n",
       "    307,\n",
       "    257,\n",
       "    4498,\n",
       "    4582,\n",
       "    4583,\n",
       "    50808],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 26,\n",
       "   'seek': 11456,\n",
       "   'start': 123.44,\n",
       "   'end': 129.84,\n",
       "   'text': ' that takes the flatten 28x28 image and transforms it to an output of 512. This layer is followed by a',\n",
       "   'tokens': [50808,\n",
       "    300,\n",
       "    2516,\n",
       "    264,\n",
       "    24183,\n",
       "    7562,\n",
       "    87,\n",
       "    11205,\n",
       "    3256,\n",
       "    293,\n",
       "    35592,\n",
       "    309,\n",
       "    281,\n",
       "    364,\n",
       "    5598,\n",
       "    295,\n",
       "    1025,\n",
       "    4762,\n",
       "    13,\n",
       "    639,\n",
       "    4583,\n",
       "    307,\n",
       "    6263,\n",
       "    538,\n",
       "    257,\n",
       "    51128],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 27,\n",
       "   'seek': 11456,\n",
       "   'start': 129.84,\n",
       "   'end': 134.24,\n",
       "   'text': ' non-linear activation function. When activated, it means that feature might be important,',\n",
       "   'tokens': [51128,\n",
       "    2107,\n",
       "    12,\n",
       "    28263,\n",
       "    24433,\n",
       "    2445,\n",
       "    13,\n",
       "    1133,\n",
       "    18157,\n",
       "    11,\n",
       "    309,\n",
       "    1355,\n",
       "    300,\n",
       "    4111,\n",
       "    1062,\n",
       "    312,\n",
       "    1021,\n",
       "    11,\n",
       "    51348],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 28,\n",
       "   'seek': 11456,\n",
       "   'start': 134.24,\n",
       "   'end': 138.88,\n",
       "   'text': ' and outputs the node, otherwise it just outputs zero. And finally, we finish with a fully connected',\n",
       "   'tokens': [51348,\n",
       "    293,\n",
       "    23930,\n",
       "    264,\n",
       "    9984,\n",
       "    11,\n",
       "    5911,\n",
       "    309,\n",
       "    445,\n",
       "    23930,\n",
       "    4018,\n",
       "    13,\n",
       "    400,\n",
       "    2721,\n",
       "    11,\n",
       "    321,\n",
       "    2413,\n",
       "    365,\n",
       "    257,\n",
       "    4498,\n",
       "    4582,\n",
       "    51580],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 29,\n",
       "   'seek': 11456,\n",
       "   'start': 138.88,\n",
       "   'end': 143.04,\n",
       "   'text': ' layer that outputs the 10 labels the model is trying to predict. With these pieces in place,',\n",
       "   'tokens': [51580,\n",
       "    4583,\n",
       "    300,\n",
       "    23930,\n",
       "    264,\n",
       "    1266,\n",
       "    16949,\n",
       "    264,\n",
       "    2316,\n",
       "    307,\n",
       "    1382,\n",
       "    281,\n",
       "    6069,\n",
       "    13,\n",
       "    2022,\n",
       "    613,\n",
       "    3755,\n",
       "    294,\n",
       "    1081,\n",
       "    11,\n",
       "    51788],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0840571195559394,\n",
       "   'compression_ratio': 1.7492447129909365,\n",
       "   'no_speech_prob': 0.0047545782290399075},\n",
       "  {'id': 30,\n",
       "   'seek': 14304,\n",
       "   'start': 143.04,\n",
       "   'end': 147.67999999999998,\n",
       "   'text': ' that next step is to define a forward method that describes the flow of data, and now instantiate',\n",
       "   'tokens': [50364,\n",
       "    300,\n",
       "    958,\n",
       "    1823,\n",
       "    307,\n",
       "    281,\n",
       "    6964,\n",
       "    257,\n",
       "    2128,\n",
       "    3170,\n",
       "    300,\n",
       "    15626,\n",
       "    264,\n",
       "    3095,\n",
       "    295,\n",
       "    1412,\n",
       "    11,\n",
       "    293,\n",
       "    586,\n",
       "    9836,\n",
       "    13024,\n",
       "    50596],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14715951139276678,\n",
       "   'compression_ratio': 1.58008658008658,\n",
       "   'no_speech_prob': 0.00043724410352297127},\n",
       "  {'id': 31,\n",
       "   'seek': 14304,\n",
       "   'start': 147.67999999999998,\n",
       "   'end': 152.64,\n",
       "   'text': ' the model to a GPU, and pass its input data. This will automatically call its forward method,',\n",
       "   'tokens': [50596,\n",
       "    264,\n",
       "    2316,\n",
       "    281,\n",
       "    257,\n",
       "    18407,\n",
       "    11,\n",
       "    293,\n",
       "    1320,\n",
       "    1080,\n",
       "    4846,\n",
       "    1412,\n",
       "    13,\n",
       "    639,\n",
       "    486,\n",
       "    6772,\n",
       "    818,\n",
       "    1080,\n",
       "    2128,\n",
       "    3170,\n",
       "    11,\n",
       "    50844],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14715951139276678,\n",
       "   'compression_ratio': 1.58008658008658,\n",
       "   'no_speech_prob': 0.00043724410352297127},\n",
       "  {'id': 32,\n",
       "   'seek': 14304,\n",
       "   'start': 152.64,\n",
       "   'end': 157.04,\n",
       "   'text': ' for training and prediction. Congratulations, you just built a neural network. This has been',\n",
       "   'tokens': [50844,\n",
       "    337,\n",
       "    3097,\n",
       "    293,\n",
       "    17630,\n",
       "    13,\n",
       "    9694,\n",
       "    11,\n",
       "    291,\n",
       "    445,\n",
       "    3094,\n",
       "    257,\n",
       "    18161,\n",
       "    3209,\n",
       "    13,\n",
       "    639,\n",
       "    575,\n",
       "    668,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14715951139276678,\n",
       "   'compression_ratio': 1.58008658008658,\n",
       "   'no_speech_prob': 0.00043724410352297127},\n",
       "  {'id': 33,\n",
       "   'seek': 14304,\n",
       "   'start': 157.04,\n",
       "   'end': 161.84,\n",
       "   'text': ' PyTorch in 100 seconds. Thanks for watching, and I will see you in the next one.',\n",
       "   'tokens': [51064,\n",
       "    9953,\n",
       "    51,\n",
       "    284,\n",
       "    339,\n",
       "    294,\n",
       "    2319,\n",
       "    3949,\n",
       "    13,\n",
       "    2561,\n",
       "    337,\n",
       "    1976,\n",
       "    11,\n",
       "    293,\n",
       "    286,\n",
       "    486,\n",
       "    536,\n",
       "    291,\n",
       "    294,\n",
       "    264,\n",
       "    958,\n",
       "    472,\n",
       "    13,\n",
       "    51304],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.14715951139276678,\n",
       "   'compression_ratio': 1.58008658008658,\n",
       "   'no_speech_prob': 0.00043724410352297127}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "413758d4-c321-424e-a1ab-7e6f18ce32a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "def get_word_len(word):\n",
    "    return len(word)\n",
    "\n",
    "print(get_word_len('will'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9796039-b949-4cb3-84d6-b40935f42f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'will'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription['text'][484:484+4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "81dcf143-95a0-4d05-910e-395dc7726119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_word_indices(model_output, words):\n",
    "    word_findings = []\n",
    "    for word in words:\n",
    "        word_findings += [i.start() for i in re.finditer(word, model_output['text'])]\n",
    "    \n",
    "    return word_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "283e572e-b500-43b8-9b2a-c678851d2498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = ['will', 'Thanks', 'watching']\n",
    "list_ = find_word_indices(transcription, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf5a87-2317-412b-ab7a-fea5a2624760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
