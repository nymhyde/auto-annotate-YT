 PyTorch, an open source deep learning framework used to build some of the world's most famous artificial intelligence products. It was created at the MetaAI Research Lab in 2016, but is actually derived from the Lua-based Torch Library that dates back to 2002. Fundamentally, it's a library for programming with tensors, which are basically just multi-dimensional arrays that represent data and parameters in deep neural networks. Sounds complicated, but its focus on usability will have you training machine learning models with just a few lines of Python. In addition, it facilitates high performance parallel computing on a GPU thanks to NVIDIA's CUDA platform. Developers love prototyping with it because it supports a dynamic computational graph, allowing models to be optimized at runtime. It does this by constructing a directed acyclic graph consisting of functions that keeps track of all the executed operations on the tensors, allowing you to change the shape, size and operations after every iteration if needed. PyTorch has been used to train models for computer vision AI like Tesla Autopilot, image generators like StableDiffusion, and speech recognition models like OpenAI Whisper, just to name a few. To get started, install PyTorch and optionally CUDA if you want to accelerate computing on your GPU. Now, import it into a Python file or notebook. Like I mentioned, a tensor is similar to a multi-dimensional array. Create a 2D array or matrix with Python, then use Torch to convert it into a tensor. Now we can run all kinds of computations on it, like we might convert all these integers into random floating points. We can also perform linear algebra by taking multiple tensors and multiplying them together. What you came here to do though is build a deep neural network, like an image classifier. To handle that, we can define a new class that inherits from the neural network module class. Inside the constructor, we can build it out layer by layer. The flatten layer will take a multi-dimensional input, like an image, and convert it to one dimension. From there, sequential is used to create a container of layers that the data will flow through. The container has multiple nodes, where each node is like its own mini statistical model. As each data point flows through it, it'll try to guess the output and gradually update a mapping of weights to determine the importance of a given variable. Linear is a fully connected layer that takes the flattened 28 by 28 image and transforms it to an output of 512. This layer is followed by a non-linear activation function. When activated, it means that feature might be important and outputs the node, otherwise it just outputs zero. And finally, we finish with a fully connected layer that outputs the 10 labels the model is trying to predict. With these pieces in place, the next step is to define a forward method that describes the flow of data. And now instantiate the model to a GPU and pass it some input data. This will automatically call its forward method for training and prediction. Congratulations, you just built a neural network. This has been PyTorch in 100 seconds. Thanks for watching, and I will see you in the next one.